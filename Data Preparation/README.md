
# Data Preparation

### What is Exploratory Data Analysis (EDA)?
While classical statistics focused primarily on inference, i.e. the process of drawing conclusions about large datasets on the basis of small samples, exploratory data analysis or data analysis was a field (of which inference is a part) that began and gained momentum on the basis of work done by John W. Tukey. In 1962, he published a paper [The Future of Data Analysis](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177704711), and in 1977 a book, [Exploratory Data Analysis](https://www.amazon.com/Exploratory-Data-Analysis-John-Tukey/dp/0201076160) (fun fact: He also coined the terms 'bit'(**bi**nary digi**t**) and 'software'). Hence EDA is a process of analyzing data sets to summarize their characterestics, mathematically or visually. [1]

### Understanding the data
The data that we will deal in this course comes from sources in the form of raw unstructured data which can't be understood by a software without refinement. Examples include electronic medical records (EMRs), images (jpegs), instant messages, etc. These types of data do not have a strict data model to adhere to. To convert this data to structured data such as ordered list, database table or spreadsheets, we must do the following -  
1. __Identify data types__
    - __Numeric__: This can be continuous or discrete numerical values. For e.g. continuous such as temperature, discrete such as count of students in a classroom.
    - __Categorical__: This type of data takes a fixed set of values. For e.g. types of car (Hatchback, Sedan, SUV), types of diabetes etc.
    - __Ordinal__: This type of data has strict ordering among its elements. For e.g. rating of a movie (1,2,3,4,5). Binary and ordinal data is type of categorical data.
    
    Correct classification of data is important to determine method for data analysis, statistical model and visualization to represent the data.

    ---
    Additional Reading
    - [SQL Data Types](w3schools.com/sql/sql_datatypes.asp)
    - [Python Data Types](https://docs.python.org/3/library/datatypes.html)
    ---

2. __Fit the dataset into a structured object__
    Once we have identified the type of data, we must fit the data either in a rectangular 2D matrix or a non-rectangular data structure like a graph. 
    - __Rectangular data objects__
    
        Examples of rectangular 2D objects are spreadsheets and database table. The rows indicate records and columns indicate features or variables of a data set. We will define them below for clarity.
        - __Feature__: A characteristic of the data, specified in columns of a table, usually an independent variable. Also known as a variable, predictor, input or attribute.
        - __Outcome__: This is a dependent variable, usually a function of the independent variables or features. Outcome specifies the ouput or result of data analysis exercise. Also known as response, target.
        - __Records__: Each row in the data set is a record. Also known as observation, sample, case.
        Rectangular data in Python can be rendered using dataframe object of the [Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) library. Data frame can be created from dictionary (from_dict), from tuples and record arrays (from_record).
        
            ```python
            >>> import pandas as pd
            >>> data = {'col1': [1, 2], 'col2': [3, 4]}     # dictionary object
            >>> df = pd.DataFrame.from_dict(data)           # data frame created from dictionary object
            >>> df
               col1  col2
            0     1     3
            1     2     4
            ```
    ---
    Additional Reading
    - [DataFrame in Python](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)
    - [DataFrame from Dict](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict)
    - [DataFrame from Records](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records)
    ---

    - __Non rectangular data objects__
        - __Time series data__: Time series is a series of data points indexed in the order of time. This data is generated by successive measurements of the same variable, taken usually at equally spaced time instances. For e.g. person's heart rate during the day, daily closing price of a company stock, hourly reading of air temperature, etc. Data generated by sensors in the internet of things will mostly be a time series data.
        - __Spatial data structure__: Spatial data consists of spatial objects made up of points, lines, regions, rectangles, surfaces, volumes, and even data of higher dimension which includes time. These are usually used in mapping and location analytics. Examples of spatial data include cities, rivers, roads, counties, states, crop coverages, mountain ranges, parts in a CAD system, etc. [4]. The reason spatial data needs a spatial data structure is to accomodate queries which involve space occupied by the data. These data structures can be queried using multiple keys. 
        - __Graphs__: These data structures are used for data that represents a network. A datapoint a network may be related to one or many datapoints in some form, for e.g. a social network of friends, a physical railway network in a country. Graphs usually represented in the form of ajacency list are used to store/represent physical, social or abstract relationships.
        
        In the rest of this lab we will focus only on rectangular data.
        
Once, we have converted the raw data to structured data, we can start analyzing the data. 

### Exploring Numerical Data
1. Analyzing data in a single number
    1. __Finding estimates of location__: A feature/variable can be characterized by the estimate of its' data points' location or central tendency. _An estimate of location is said to be robust when it is not sensitive to extreme values or outliers_. Mean and median are most common estimates of location, but are they robust enough?
        - __Mean__: Sum of all values divided by the number of values. In the equation below x-bar represents the mean of sample from a population. _n_ refers to the number of records or observation the sample.
       
             ![](https://latex.codecogs.com/svg.latex?\inline&space;Mean&space;=&space;\bar{x}&space;=&space;\frac{\sum_{i}^{n}x_i}{n})
             
             - __Trimmed Mean__: A more robust estimate than mean is trimmed mean. It is calculated by dropping a fixed number of _sorted values_ at each end, and then taking an average of the remaining values. The objective is to get rid of outliers or extreme values from both ends of a sequence. The formula below assumes _p_ smallest and _p_ largest values are omitted.
             
                  ![](https://latex.codecogs.com/svg.latex?\inline&space;Trimmed\-&space;&space;mean&space;=&space;\bar{x}&space;=&space;\frac{\sum_{i=p&plus;1}^{n-p}x_i}{n-2p})
                  
             - __Weighted Mean__: Each data value in the sample is multiplied with a pre-determined weight and their sum is divided by the sum of weights. In the formula below, _w_ is the weight of a data point.
             
                  ![](https://latex.codecogs.com/svg.latex?\inline&space;Weighted\-&space;&space;mean&space;=&space;\bar{x_w}&space;=&space;\frac{\sum_{i=1}^{n}w_ix_i}{\sum_{i}^{n}w_i})
                  
               Practical use of weighted mean - use it for compensation of unreliable data sources, for e.g.: 
               
                    1. Give lower weight to highly variable values, as they can influence the estimate. For example, if a sensor is inaccurate, then among all sensors it can be given a lower weight. [3]
                    2. Give higher weight to an under-represented group to equally represent all groups.
                    
        - __Median__: The middle value in a sorted list of data is the median of that list of data. It only depends on a single value in a dataset, unlike the mean which depends on all the values, so we can say mean is more sensitive to data. Hence, we can say that median is a more robust estimate of location. For e.g. to estimate a typical household income in neighborhoods in the bay area, if we use mean to estimate the household income in the neighborhood where Mark Zuckerburg lives, and say, San Jose, we will get a very different result just because of one outlier in Menlo Park. However, if we use median, the observation in the middle will remain the same irrespective of outliers. [3]. Note, we can also achieve a similar result with a trimmed mean.
        
             - __Weighted Median__: Just like in the calculation of a median, the data is sorted. Each data point also has a corresponding weight. The weighted median is such that sum of weights for the left data points is equal to the sum of weights for all the data points on its right.
             
        ![mean-median-mode-meme](https://miro.medium.com/max/1398/1*JVuKIOTL3YHsSlW_hdtvxg.png)
        
        The key factors in identifying the appropriate estimate of locations is **robustness**.
    2. Finding estimates of variability
        - Standard deviation
        - Estimate based on percentiles
2. Analyzing data as a distribution
    - Percentiles
    - Boxplots
    - Frequency tables
    - Histograms
    - Density estimates.

### Exploring Binary/Categorical Data
1. Analyzing data in a single number
    1. Mode
    2. Expected value
2. Analyzing data as a distribution
    1. Bar charts
    2. Pie charts

### References
[[1.]](https://en.wikipedia.org/wiki/Exploratory_data_analysis) Exploratory Data Analysis

[[2.]](https://www.techopedia.com/definition/13865/unstructured-data) Unstructured data definition

[[3.]](https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/1491952962) Practical Statistics for Data Scientists

[[4.]](http://www.cs.umd.edu/~hjs/pubs/kim.pdf) Spatial Data Structures
